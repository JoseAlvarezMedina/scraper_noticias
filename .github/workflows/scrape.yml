name: Scraper CI

on:
  schedule:
    - cron: '0 */6 * * *'  # ⏱️ Ejecuta cada 6 horas
  workflow_dispatch:

jobs:
  lint-and-test:
    name: Lint & Test
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}

      - name: Install dependencies + dev tools
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov flake8

      - name: Lint with flake8
        run: flake8 . --exclude=venv

      - name: Run pytest
        run: pytest --maxfail=1 --disable-warnings -q

  scrape-and-push:
    name: Scrape & Publish Artifacts
    needs: lint-and-test
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Scrapy spider
        run: scrapy crawl titulares -s LOG_LEVEL=INFO

      - name: Upload CSV & DB as artifacts
        uses: actions/upload-artifact@v3
        with:
          name: noticias-data
          path: |
            noticias.csv
            noticias.db
